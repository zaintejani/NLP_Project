dfbeta(u)
influence(u)
u<p-lm(x~y)
u<-lm(x~y)
influence(u)
11.72/1.344
1.344/11.72
install.packages("lmtest")
a<-lm(mpg ~ wt+factor(cyl), data = mtcars)
b<-lm(factor(cyl)~wt, data = mtcars)
library(lmtest)
?lrtest
lrtest(a,b)
coef(lm(y~x))
coef(lm(y[1:4]~x[1:4]))
lm(mpg~am)
lm(mpg~am, data=mtcars)
lm(mpg~am+wt, data=mtcars)
lm(mpg~am+wt+hp, data=mtcars)
a<-lm(mpg ~ wt+factor(cyl), data = mtcars)
b<-lm(mpg ~ wt*factor(cyl), data = mtcars)
a
b
lrtest(a,b)
s1<-c(140,138,150,148,135)
s2<-c(132,135,151,146,130)
?t.test
mean(s2)-mean(s1)
t.test(x=s1,y=s2, alternative="two.sided")
t.test(x=s1,y=s2, alternative="two.sided", paired=TRUE)
1100+c(1,-1)*qt(0.975)*10
1100+c(1,-1)*qt(0.975, df=8)*10
?pbinom
qbinom(c(1,1,1,0),4,0.75)
qbinom(0.75,4,0.75)
power.t.test(n=100, delta=0.01, sd=0.04)
power.t.test(n=100, delta=0.01, sd=0.04, alternative="lower")
power.t.test(n=100, delta=0.01, sd=0.04, alternative="one.sided")
power.t.test(n=100, delta=-0.01, sd=0.04, alternative="one.sided")
power.t.test(n=100, delta=0.01, sd=0.04, alternative="one.sided")
power.t.test(power=0.9, delta=0.01, sd=0.04, alternative="one.sided")
power.t.test(power=0.9, delta=0.01, sd=0.04, alternative="one.sided", sig.level=0.1)
power.t.test(power=0.9, delta=-0.01, sd=0.04, alternative="one.sided")
power.t.test(power=0.9, delta=0.01, sd=0.04, alternative="one.sided")
power.t.test(power=0.9, delta=0.01, sd=0.04)
power.t.test(power=0.9, delta=0.01, sd=0.04, alternative="one.sided")
?pt
power.t.test(power=0.9, delta=0.1, sd=0.04, alternative="one.sided")
power.t.test(power=0.9, delta=0.01, sd=0.04, alternative="one.sided")
power.t.test(power=0.9, n=180, sd=0.04, alternative="one.sided")
qt(c(0.1,0.9))
qt(c(0.1,0.9), df=8)
1123-1077
69/1.396815
1123-23
1077+23
t.test(1078,mu=1100, df=8)
pt(1078)
pt(1078, df=8)
pt(0.5, df=8)
pt(0.75, df=8)
?t.test
t.test(x=rnorm(n=9,mu=-3,sd=1),y=rnorm(n=9,mu=1,sd=1.8),var.equal=TRUE)
?rnorm
t.test(x=rnorm(n=9,mean=-3,sd=1),y=rnorm(n=9,mean=1,sd=1.8),var.equal=TRUE)
t.test(x=rnorm(n=9,mean=-3,sd=1),y=rnorm(n=9,mean=1,sd=1.8),var.equal=TRUE)
var(c(1,0,1,1))
var(c(1,1,1,0))
?pt
pt(2,df=3)
pnorm(2)
1-pt(2,df=3)
sqrt(0.25)
pt(1,df=3)
pt(1,df=3, lower.tail=FALSE)
choose(4,3)*0.5^4+choose(4,4)*0.5^4
lambda=1
ppois(9,1,lower.tail=FALSE)
ppois(99,1,lower.tail=FALSE)
ppois(9,1,lower.tail=FALSE)
ppois(1786,17.87,lower.tail=FALSE)
ppois(1786,10,lower.tail=FALSE)
ppois(9,1,lower.tail=FALSE)
ppois(10,17.87,lower.tail=FALSE)
?ppois
ppois(10,1,lower.tail=FALSE)
ppois(17.87,10,lower.tail=FALSE)
ppois((10/1787),0.1)
ppois((10/1787),0.1, lower.tail=FALSE)
ppois((10/1787),0.1,)
ppois(10,17.87)
power.t.test(n=100,delta=0.01,sd=0.04)
power.t.test(n=100,delta=0.01,sd=0.04, alternative="one.sided")
power.t.test(power=0.9,delta=0.01,sd=0.04, alternative="one.sided")
power.t.test(power=0.9,delta=0.1,sd=0.04, alternative="one.sided")
power.t.test(power=0.9,delta=0.01,sd=0.04, alternative="one.sided")
power.t.test(power=0.9,n=180,sd=0.04, alternative="one.sided")
power.t.test(power=0.9,n=160,sd=0.04, alternative="one.sided")
power.t.test(power=0.9,delta=0.01,sd=0.04, alternative="one.sided")
?power.t.test
power.t.test(power=0.9,delta=0.01,sd=0.04, alternative="one.sided", type="one.sample")
power.t.test(n=100,delta=0.01,sd=0.04, alternative="one.sided", type="one.sample")
?glm
library(MASS)
?shuttle
data(shuttle)
class(shuttle)
colnames(shuttle)
?glm
class(shuttle$wind)
levels(shuttle$wind)
class(shuttle$use)
levels(shuttle$use)
as.numeric(levels(shuttle$use))
as.numeric(shuttle$use)
shuttle$use[1:10]
shuttle$auto<-as.numeric(shuttle$use)
shuttle$auto[shuttle$auto==2]<-0
shuttle$auto
glm(shuttle$auto~shuttle$wind)
glm(shuttle$auto~shuttle$wind=="head")
glm(shuttle$auto~shuttle$wind=="tail")
glm(shuttle$auto~shuttle$wind=="head"+shuttle$wind=="tail")
glm(shuttle$auto~shuttle$wind=="head"+shuttle$wind)
glm(shuttle$auto~shuttle$wind=="head", family="binomial")
glm(shuttle$auto~shuttle$wind=="tail", family="binomial")
colnames(shuttle)
glm(shuttle$auto~shuttle$wind=="head"+shuttle$magn, family="binomial")
class(shuttle$magn)
levels(shuttle$magn)
as.numeric(shuttle.magn)
as.numeric(shuttle$magn)
shuttle$magn
glm(shuttle$auto~shuttle$wind=="head"+as.numeric(shuttle$magn), family="binomial")
glm(shuttle$auto~shuttle$wind+as.numeric(shuttle$magn), family="binomial")
glm(1-shuttle$auto~shuttle$wind+as.numeric(shuttle$magn), family="binomial")
library(datasets)
?InsectSprays
data(InsectSprays)
class(InsectSprayss)
data(InsectSprays)
class(InsectSprays)
colnames(InsectSprays)
class(InsectSprays$count)
class(InsectSprays$spray)
glm(count~spray,data=InsectSprays,family="Poisson")
?family
glm(count~spray,data=InsectSprays,family="poisson")
glm(shuttle$auto~shuttle$wind=="head", family="binomial")
glm(shuttle$auto~shuttle$wind, family="binomial")
summary(glm(shuttle$auto~shuttle$wind, family="binomial"))
summary(glm(shuttle$auto~shuttle$wind=="head", family="binomial"))
summary(glm(shuttle$auto~shuttle$wind=="head"+as.numeric(shuttle$magn), family="binomial"))
summary(glm(shuttle$auto~shuttle$wind+as.numeric(shuttle$magn), family="binomial"))
summary(glm(shuttle$auto~as.numeric(shuttle$wind=="head")+as.numeric(shuttle$magn), family="binomial"))
glm(count~spray,data=InsectSprays,family="Poisson")
glm(count~spray,data=InsectSprays,family="poisson")
glm(count~spray %in% c(1,2),data=InsectSprays,family="poisson")
glm(count~spray=="sprayA",data=InsectSprays,family="poisson")
glm(count~spray,data=InsectSprays,family="poisson")
levels(InsectSpray$spray)
levels(InsectSprays$spray)
glm(count~spray=="A",data=InsectSprays,family="poisson")
glm(count~spray=="B",data=InsectSprays,family="poisson")
??knot point
??knot
?glm
count<-round(runif(mean=10,sd=2))
count<-round(runif(10,2))
count<-round(rnorm(10,2))
count<-round(rnorm(n=100,10,2))
?rbinom
rbinom(100,1,0.5)
x1<-rbinom(100,1,0.5)
t<-1:100
glm(count ~ x + offset(t), family = poisson)
glm(count ~ x1 + offset(t), family = poisson)
t2<-log(10)+t
glm(count ~ x1 + offset(t2), family = poisson)
x<- -5:5
y <- c(5.12, 3.93, 2.67, 1.87, 0.52, 0.08, 0.93, 2.05, 2.54, 3.87, 4.97)
cbind(x,y)
a<-cbind(x,y)
b<-a[6:11,]
b[2]/b[1]
b<-b[2:6]
b[2]/b[1]
splineTerms<-sapply(0,function(knot)(x>knot)*(x-knot))
xmat<-cbind(1,x,splineTerms)
yhat<-predict(lm(y~xmat-x))
yhat
x <- c(0.18, -1.54, 0.42, 0.95)
w <- c(2, 1, 3, 1)
a<-x*w
sum(a)/sum(w)
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
lm(y~x)
library(datasets)
data(mtcars)
class(mtcars)
lm(mpg~wt, data=mtcars)
x <- c(8.58, 10.46, 9.01, 9.64, 8.86)
a<-(x-mean(x))/sd(x)
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
lm(y~x)
mean(x)
lm(x~y)
lm(y~x)
source('~/.active-rstudio-document')
ind<-grep("IL,colnames(training")
ind<-grep("IL",colnames(training))
ind
colnames(ind)
colnames(training)[ind]
ind<-ind[1:12]
colnames(training)[ind]
train2<-training[,ind]
?preProcess)
?preProcess
b<-preProcess(train2,thresh=0.8)
b
b$PCA
summary(b)
b$mean
b$method
b<-preProcess(train2,method="pca")
b
b<-preProcess(train2,method="pca", thresh=0.8)
v
b
source('~/.active-rstudio-document')
hist(training$Super)
min(training$Super)
length(training$Super[training$Super==0])
colnames(training)
library(Hmisc)
colnames(training)
BFS<-cut2(training$Blast, g=10)
FA<-cut2(training$Fly, g=10)
W<-cut2(training$Water, g=10)
SP<-cut2(training$Super, g=10)
CA<-cut2(training$Coarse, g=10)
FA2<-cut2(training$Fine, g=10)
A<-cut2(training$Age, g=10)
qplot(Cement, CompressiveStrength, data=training, color=BFS)+geom_smooth(method="lm")
qplot(Cement, CompressiveStrength, data=training, color=FA)+geom_smooth(method="lm")
qplot(Cement, CompressiveStrength, data=training, color=W)+geom_smooth(method="lm")
qplot(Cement, CompressiveStrength, data=training, color=SP)+geom_smooth(method="lm")
qplot(Cement, CompressiveStrength, data=training, color=CA)+geom_smooth(method="lm")
qplot(Cement, CompressiveStrength, data=training, color=FA2)+geom_smooth(method="lm")
qplot(Cement, CompressiveStrength, data=training, color=A)+geom_smooth(method="lm")
library(datasets)
data(mtcars)
class(mtcars)
levels(as.factor(mtcars$cyl))
lm(mpg~as.factor(cyl)+wt)
lm(mpg~as.factor(cyl)+wt, data=mtcars)
lm(mpg~as.factor(cyl), data=mtcars)
c<-lm(mpg~as.factor(cyl)*wt, data=mtcars)
summary(c)
x <- c(0.586, 0.166, -0.042, -0.614, 11.72)
y <- c(0.549, -0.026, -0.127, -0.751, 1.344)
?hat
hatvalues(lm(y~x))
dfbeta(lm(y~x))
dfbeta(lm(x~y))
dfbeta(lm(y~x))
lm(mpg ~ I(wt * 0.5) + factor(cyl), data = mtcars)
lm(mpg ~ I(wt * 1) + factor(cyl), data = mtcars)
f1<-lm(mpg~as.factor(cyl)+wt, data=mtcars)
f2<-lm(mpg~as.factor(cyl)*wt, data=mtcars)
anova(f1,f2)
source('~/.active-rstudio-document')
a<-segmentationOriginal
class(a$case)
class(a$Case)
levels(a$Case)
train<-a[a$Case=="Train",]
test<-a[a$Case=="Test",]
?rpart
?predict
colnames(train)
class(train$Class)
levels(train$Class)
Tree<-rpart(class~., data=train)
?caret
?rpart
x<-train(Class~., data=train, method="rpart")
x
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
a
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
a<-segmentationOriginal
train<-a[a$Case=="Train",]
test<-a[a$Case=="Test",]
set.seed(125)
x<-train(Class~., data=train, method="rpart")
x
print(x$finalModel)
install.packages(pgmm)
install.packages("pgmm")
source('~/.active-rstudio-document')
colnames(o;ive)
colnames(oive)
colnames(olive)
class(olive$Area)
summary(olives$Area)
summary(olive$Area)
olives$Area[1:10]
olive$Area[1:10]
olive$Area[90:100]
x<-train(Area~., data=olive, method="rpart")
?tree
?predict
args(prdict)
args(predict)
predict(x, newdata=as.data.frame(t(colMeans(olive)))
)
?train
source('~/.active-rstudio-document')
install.packages(ElemStatLearn)
install.packages("ElemStatLearn")
source('~/.active-rstudio-document')
set.seed(13234)
colnames(trainSA)
set.seed(13234)
x<-train(chd~age+alcohol+obesity+tobacco+typea+ldl, data=trainSA, method="glm", family="binomial")
x$finalModel
x$fitted
x$Fitted
x
summary(x)
a<-predict(x, newdata=trainSA)
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
misClass(trainSA$chd,a)
missClass(trainSA$chd,a)
b<-predict(x, newdata=testSA)
missClass(trainSA$chd,b)
source('~/.active-rstudio-document')
class(vowel.test)
class(vowel.train)
colnames(vowel.train)
set.seed(33833)
x<-train(y~., data=vowel.train, method="rf")
source('~/.active-rstudio-document')
class(vowel.train)
class(vowel.test)
colnames(vowel.train)
library(randomForest)
set.seed(33833)
randomForest(y~., data=vowel.train)
varImp(x)
set.seed(33833)
x<-randomForest(y~., data=vowel.train)
varImp(x)
x
?varImp
varImp(x)
source('~/.active-rstudio-document')
library(randomForest)
class(vowel.test)
class(vowel.train)
class(vowel.train$y)
class(vowel.train$y)<-factor
vowel.train$y<-as.factor(vowel.train$y)
vowel.test$y<-as.factor(vowel.test$y)
class(vowel.train$y)
levels(vowel.train$y)
set.seed(33833)
x<-randomForest(y~., data=vowel.train)
varImp(x)
library(caret)
varImp(x)
a<-varImp(x)
class(a)
?order
source('~/.active-rstudio-document')
class(vowel.train)
class(vowel.test)
library(caret)
class(vowel.train$y)
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
?predict
pred1<-predict(mod1, data=vowel.test)
pred1<-predict(mod1, newdata=vowel.test)
pred2<-predict(mod2, newdata=vowel.test)
pred1
?confusionMatrix
confusionMatrix(pred1, reference=vowel.test$y)
confusionMatrix(pred2, reference=vowel.test$y)
source('~/.active-rstudio-document')
set.seed(233)
mod1<-train(CompressiveStrength~., method="lasso", data=training)
plot(mod1)
plot(mod1$finalModel)
library(e1071)
??e1071
?svm
?rm
source('~/.active-rstudio-document')
set.seed(325)
mod1<-svm(CompressiveStrength~.,data=training)
pred1<-predict(mod1, newdata=testing)
RMSE1<-sqrt(sum((pred1 - training$CompressiveStrength)^2))
confusionMatrix(pred1, testing$CompressiveStrength)
confusionMatrix(pred1, reference=testing$CompressiveStrength)
pred1
summary(pred1)
class(pred1)
RMSE1 = sqrt(sum((pred1 - testing$CompressiveStrength)^2))
RMSE1
install.packages(forecast)
install.packages("forecast")
library(forecast)
source('~/.active-rstudio-document')
install.packages(lubridate)
install.packages("lubridate")
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
?bats
colnames(testing)
class(X)
class(training$X)
class(training$date)
training$X[1:100]
levles(training$date)
levels(training$date)
?accuracy
accuracy(mod1)
source('~/.active-rstudio-document')
set.seed(325)
mod1<-svm(CompressiveStrength~.,data=training)
pred1<-predict(mod1, newdata=testing)
accuracy(pred1)
?accuracy
accuracy(pred1, testing$CompressiveStrength)
?dgamma
?colSums
?getMethod()
getMethod(mean)
getMethod("mean")
?colSums
?lm
?dgamma
?predict
inGeneric(colSums)
isGeneric(colSums)
?isGeneric
isGeneric("colSums")
isGeneric("lm")
isGeneric("predict")
isGeneric("dgamma")
isGeneric("mean")
library(tm);library(stylo);library(SnowballC)
Corp2<-VCorpus(DirSource("./Train/Sample"))
setwd("./Rdirectory/NLP_Project/Data and cleaning scripts")
Corp2<-VCorpus(DirSource("./Train/Sample"))
Corp2<-tm_map(Corp2, content_transformer(tolower))
BLEEP<-readLines("./profanity.txt");Corp2<-tm_map(Corp2, removeWords, BLEEP)
Corp2<-tm_map(Corp2, stripWhitespace)
Corp2<-tm_map(Corp2, removeNumbers)
Corp2<-tm_map(Corp2, removePunctuation)
Corp2<-tm_map(Corp2, stemDocument)
Corp1<-tm_map(Corp2, removeWords,stopwords("english"))
tCorp<-txt.to.words(Corp2)
UniGram<-txt.to.words(Corp1)
BiGram<-make.ngrams(tCorp,ngram.size=2)
TriGram<-make.ngrams(tCorp,ngram.size=3)
QuadGram<-make.ngrams(tCorp,ngram.size=4)
PentGram<-make.ngrams(tCorp,ngram.size=5)
UG<-as.data.frame(table(UniGram));UG<-UG[order(UG$Freq, decreasing=TRUE),]
BG<-as.data.frame(table(BiGram));BG<-BG[order(BG$Freq, decreasing=TRUE),]
TG<-as.data.frame(table(TriGram));TG<-TG[order(TG$Freq, decreasing=TRUE),]
TG<-as.data.frame(table(TriGram));TG<-TG[order(TG$Freq, decreasing=TRUE),]
QG<-as.data.frame(table(QuadGram));QG<-QG[order(QG$Freq, decreasing=TRUE),]
rm("UniGram","BiGram","TriGram","QuadGram")
PG<-as.data.frame(table(PentGram));PG<-PG[order(PG$Freq, decreasing=TRUE),]
rm("Corp1","Corp2","PentGram","tCorp","BLEEP")
write.table(UG,"./UniGram.txt")
write.table(BG,"./BiGram.txt")
write.table(TG,"./TriGram.txt")
write.table(QG,"./QuadGram.txt")
write.table(PG,"./PentGram.txt")
rm("UG")
UG<-read.table("./UniGram.txt", header=TRUE)
head(UG)
UG0<-UG[UG$Freq>1,]
tail(UG0)
BG0<-BG[BG$Freq>1,]
TG0<-TG[TG$Freq>1,]
QG0<-QG[QG$Freq>1,]
PG0<-PG[PG$Freq>1,]
object.size(UG)/object.size(UG0)
object.size(PG)/object.size(PG0)
nrow(PG)/nrow(PG0)
write.table(UG0,"./UniGramShort.txt")
write.table(BG0,"./BiGramShort.txt")
write.table(TG0,"./TriGramShort.txt")
write.table(QG0,"./QuadGramShort.txt")
write.table(PG0,"./PentGramShort.txt")
head(UG0)
UGd<-head(UG0)
write.table(UGd,"./UniGramDefault.txt")
rm("UG","BG","TG","QG","PG")
UG0<-UGd
UG0<-UGd;rm("UGd")
?save.image
save(list = ls(all.names = TRUE), file = "session.RData", envir = .GlobalEnv)
